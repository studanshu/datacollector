<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_gcr_z2t_zv">
 <title>Hive Metastore</title>
 <shortdesc>The Hive Metastore destination works with the Hive Metadata processor and Hadoop FS
        destination as part of the Hive Drift Solution. The Hive Metastore destination uses metadata
        records generated by the Hive Metadata processor to create and update Hive tables. This
        enables the Hadoop FS destination to write drifting data to HDFS. </shortdesc>
 <conbody>
        <p><indexterm>destinations<indexterm>Hive Metastore </indexterm></indexterm><indexterm>Hive
                Metastore destination<indexterm>overview</indexterm></indexterm>The Hive Metastore
            destination compares information in metadata records with Hive tables, and then creates
            or updates the tables as needed. For example, when the Hive Metadata processor
            encounters a record that requires a new Hive table, it passes a metadata record to the
            Hive Metastore destination and the destination creates the table.</p>
        <p>Note that the Hive Metastore destination does not process data. It processes only
            metadata records generated by the Hive Metadata processor and must be downstream from
            the processor's metadata output stream.</p>
        <p>When you configure Hive Metastore, you define the connection information for Hive, the
            location of the Hive and Hadoop configuration files and optionally specify additional
            required properties. You can also set a maximum cache size for the destination and
            determine how new tables are created and stored.</p>
        <note>When using the destination in multiple pipelines, take care to avoid concurrent or
            conflicting writes to the same tables. </note>
    </conbody>
    <related-links>
        <link href="../Hive_Metadata/HiveDrift-Overview.dita#concept_phk_bdf_2w"/>
        <link href="../Hive_Metadata/HiveDataTypes.dita#concept_ry2_qkm_hw"/>
    </related-links>
</concept>
