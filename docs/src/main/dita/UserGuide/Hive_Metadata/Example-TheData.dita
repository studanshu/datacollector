<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_mbf_dsn_fw">
 <title>Processing Data</title>
 <shortdesc>Now what happens when you start the pipeline?</shortdesc>
 <conbody>
        <p>This pipeline is set up to write data to different tables based on the table name in the
            "tag" attribute that was added to the record headers in the earlier pipeline. </p>
        <p>Say the table names are "weblog" and "service".</p>
        <p>For each record with "weblog" as the tag attribute, the Hive Metadata processor evaluates
            the fields in the record: <ul id="ul_xv3_dkk_gw">
                <li>If the fields match the existing Hive table, it just writes the necessary
                    information into the targetDirectory and avroSchema stage attributes, and Hadoop
                    FS writes the record to the weblog table.</li>
                <li>If a record includes a new field, the processor generates a metadata record that
                    the Hive Metastore destination uses to update the weblog table to include the
                    new field. It also writes information to stage attributes so Hadoop FS can write
                    the record to the weblog table.</li>
                <li>If a record has missing fields, the processor just writes information to stage
                    attributes, and Hadoop FS writes the record to Hive with null values for the
                    missing fields.</li>
                <li>If a field has been renamed, the processor treats the field as a new field,
                    generating a metadata record that the Hive Metastore destination uses to update
                    the weblog table. And when Hadoop FS writes the record, data is written to the
                    new field and a null value to the old field.</li>
                <li>If a data type changes for an existing field, the processor treats the record is
                    treated as an error record.</li>
            </ul></p>
        <p>For each record with a "service" tag, the processor performs the same actions.</p>
        <p>If a record includes a new tag value, the Hive Metadata processor generates a metadata
            record that the Hive Metastore destination uses to create a new table. And Hadoop FS
            writes the record to the new table. </p>
 </conbody>
</concept>
