<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_php_y1d_dw">
 <title>Record Processing</title>
 <conbody>
        <p><indexterm>Hive Metadata processor<indexterm>record
                processing</indexterm></indexterm><indexterm>record processing<indexterm>Hive
                    Metadata processor</indexterm></indexterm>When processing records, Hive Metadata
            processor performs the following tasks:</p>
        <p>
            <draft-comment author="Loretta">** move to another section? **<p>The Hive Metadata
                    processor connects to a Hive instance to verify the existing table structures,
                    determines where records need to be written, and then generates metadata records
                    that enable the Hive Metastore destination to create or update the required
                    tables.</p><p>The processor also generates stage attributes in record headers.
                    The stage attributes define the directory a record is written to, the Avro
                    schema needed for the data, and when to roll an output file. These stage
                    attributes enable the Hadoop FS destination to process records based on record
                    headers.</p></draft-comment>
        </p>
        <dl>
            <dlentry>
                <dt>Evaluates the expressions that define the target table and generates metadata
                    records when necessary</dt>
                <dd>
                    <ol id="ol_npz_5dk_dw">
                        <li>For each record, the processor evaluates the expressions configured in
                            the stage to determine the database, table, and optional partition where
                            the record should be written.</li>
                        <li>If the directory describes a table that does not exist, the Hive
                            Metadata processor generates a metadata record that defines the database
                            and table that's needed and passes it through the metadata output to the
                            Hive Metastore destination.<p>The Hive Metastore destination uses
                                information in the metadata record to create the table in Hive.
                            </p></li>
                    </ol>
                </dd>
            </dlentry>
            <dlentry>
                <dt>Evaluates record structures and generates metadata records when necessary </dt>
                <dd>
                    <ol id="ol_vfj_rtx_dw">
                        <li>If the target table for the record exists, the processor also evaluates
                            the record structure and determines if it matches the Hive table
                            structure. </li>
                        <li>If the record includes compatible changes in the table structure, the
                            processor generates a metadata record that describes the table structure
                            and passes it through the metadata output to the Hive Metastore
                            destination. <p
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/P-HM-CompatChanges"
                            /></li>
                    </ol>
                </dd>
            </dlentry>
            <dlentry>
                <dt>Generates the target directories and writes the results to the record
                    header</dt>
                <dd>The processor generates the target directory for each record and writes it to
                    the targetDirectory stage attribute in the record header. <p>You can configure
                        the Hadoop FS destination to write the record to the location in the
                        targetDirectory stage attribute.</p></dd>
            </dlentry>
            <dlentry>
                <dt>Writes Avro schemas and roll requests to the record header</dt>
                <dd>
                    <ol id="ol_jxt_stx_dw">
                        <li>The processor writes the Avro schema in the avroSchema stage attribute
                            in the record header, generating new schemas for compatible changes.
                                <p>You can configure the Hadoop FS destination to write the record
                                using the Avro schema in the record header.</p></li>
                        <li>When the processor generates a new Avro schema, it also adds a roll
                            stage attribute to the record header. The roll stage attribute indicates
                            that the open file should be closed and a new file started for the new
                                schema.<p>You can configure the Hadoop FS destination to roll files
                                when encountering the roll stage attribute. </p></li>
                    </ol>
                </dd>
            </dlentry>
            <dlentry>
                <dt>Error record handling</dt>
                <dd>If the record includes incompatible changes in table structure or Avro schema,
                    such as changes in data type, the record is handled based on the error handling
                    configured for the stage.</dd>
            </dlentry>
        </dl>
 </conbody>
</concept>
