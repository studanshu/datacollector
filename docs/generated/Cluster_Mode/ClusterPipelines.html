
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode. In standalone mode, a single Data Collector process ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Cluster Pipelines"></meta><meta name="abstract" content="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode."></meta><meta name="description" content="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode."></meta><meta name="DC.Relation" scheme="URI" content="../Cluster_Mode/ClusterPipelines_title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_hmh_kfn_1s"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Cluster Pipelines</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody"><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
​
  ga('create', 'UA-53969024-1', 'auto');
  ga('send', 'pageview');
​
</script>
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines">Cluster Pipelines</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_hmh_kfn_1s">
 <h1 class="title topictitle1">Cluster Pipelines</h1>

 
 <div class="body conbody"><p class="shortdesc">A <dfn class="term">cluster pipeline</dfn> is a pipeline that runs in cluster execution mode. You
  can run a pipeline in standalone execution mode or cluster execution mode. </p>

  <p class="p">In standalone mode, a single <span class="ph">Data
                  Collector</span> process runs
   the pipeline. A pipeline runs in standalone mode by default. </p>

  <p class="p">In cluster mode, the <span class="ph">Data
                  Collector</span> uses a cluster
   manager and a cluster application to spawn additional workers as needed. Use cluster mode to read
   data from a Kafka cluster or HDFS.</p>

  <p class="p">When would you choose standalone or cluster mode? Say you want to ingest logs from applications
   servers and perform a computationally expensive transformation. To do this, you might use a set
   of standalone pipelines to stream log data from each application server to Kafka. And then use a
   cluster pipeline to process the data from the Kafka cluster and perform the expensive
   transformation.</p>

  <p class="p">Or, you might use cluster mode to move data from HDFS to another destination, such as
   Elasticsearch.</p>

  <div class="p">The origin system determines how a <span class="ph">Data
                  Collector</span> runs a cluster
   mode pipeline:<dl class="dl">
    
     <dt class="dt dlterm">Kafka cluster</dt>

     <dd class="dd">When processing data from a Kafka cluster, the <span class="ph">Data
                  Collector</span> processes
      data continuously until you stop the pipeline. This is known as cluster streaming mode. </dd>

     <dd class="dd">The <span class="ph">Data
                  Collector</span>
      runs as an application within Spark Streaming, an open source cluster-computing application.
      Spark Streaming runs on either the Mesos or YARN cluster manager to process data from a Kafka
      cluster.</dd>

     <dd class="dd">The cluster manager and Spark Streaming spawn a <span class="ph">Data
                  Collector</span> worker for
      each partition in the Kafka cluster. So each partition has a <span class="ph">Data
                  Collector</span> worker to
      process data. </dd>

     <dd class="dd">Use the Kafka Consumer origin to process data from Kafka in cluster mode.</dd>

    
   </dl>
<dl class="dl">
    
     <dt class="dt dlterm">HDFS</dt>

     <dd class="dd">When processing data from HDFS, the <span class="ph">Data
                  Collector</span> processes
      all available data and then stops the pipeline. This is known as cluster batch mode.</dd>

     <dd class="dd">The <span class="ph">Data
                  Collector</span>
      runs as an application on top of MapReduce, an open-source cluster-computing framework.
      MapReduce runs on the YARN cluster manager. </dd>

     <dd class="dd">YARN and MapReduce generate additional worker nodes as needed. MapReduce creates one map
      task for each HDFS block. </dd>

     <dd class="dd">Use the Hadoop FS origin to process data from HDFS in cluster mode.</dd>

    
   </dl>
</div>

  <p class="p">You can use any processor or destination in cluster pipelines.</p>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_rmd_hgp_cw">
 <h2 class="title topictitle2">HTTP Protocols</h2>

 
 <div class="body conbody"><p class="shortdesc">You can configure Data Collector to use HTTP or HTTPS when you run cluster pipelines. By
        default Data Collector uses HTTP.</p>

  <p class="p">To configure HTTPS when you run cluster pipelines, you must generate an SSL certificate for the
            gateway node and the worker nodes. You then specify the generated keystore file and
            keystore password file for the gateway and worker nodes in the <span class="ph">Data
                  Collector</span>
            configuration file, <samp class="ph codeph">sdc.properties</samp>. You can optionally generate a
            truststore file for the gateway and worker nodes.</p>

 </div>

    <div class="related-links"><div class="relinfo relconcepts"><strong>Related concepts</strong><br xmlns="http://www.w3.org/1999/xhtml" />
<div class="related_link"><a class="navheader_parent_path" href="../Install_Config/DCConfig.html#concept_rdt_h54_cw" title="To configure HTTPS when you run cluster pipelines, you can use a self-signed certificate. Or, you can generate an SSL certificate for the gateway node and the worker nodes. You specify the generated keystore file and keystore password file for the gateway and worker nodes in the Data Collector configuration file, sdc.properties. You can optionally generate a truststore file for the gateway and worker nodes.">Configuring HTTPS for Cluster Pipelines</a></div>
</div>
</div>
</div>
<div class="topic concept nested1" id="concept_swq_1bg_xs">
 <h2 class="title topictitle2">Kerberos Authentication for Yarn</h2>

 
 <div class="body conbody"><p class="shortdesc">If a cluster on YARN uses Kerberos authentication, make sure to configure the <span class="ph">Data
                  Collector</span> to use
    Kerberos authentication.</p>

  <p class="p">When you configure Kerberos authentication for the <span class="ph">Data
                  Collector</span>, you
      enable the <span class="ph">Data
                  Collector</span> to use Kerberos and define the principal and keytab. When Kerberos is enabled for the <span class="ph">Data
                  Collector</span>, the <span class="ph">Data
                  Collector</span>
      automatically uses Kerberos principal and keytab to connect to any YARN cluster that uses
      Kerberos.</p>

 </div>

  <div class="related-links"><div class="relinfo relconcepts"><strong>Related concepts</strong><br xmlns="http://www.w3.org/1999/xhtml" />
<div class="related_link"><a class="navheader_parent_path" href="../Install_Config/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Enabling Kerberos Authentication</a></div>
</div>
</div>
</div>
<div class="topic concept nested1" id="concept_cs4_lcg_j5">
    <h2 class="title topictitle2">Checkpoint Storage for Streaming Pipelines</h2>

    
    <div class="body conbody"><p class="shortdesc">When the <span class="ph">Data
                  Collector</span> runs a
        cluster streaming pipeline, on either Mesos or YARN, the <span class="ph">Data
                  Collector</span>
        generates and stores checkpoint metadata. The checkpoint metadata provides the offset for
        the origin.</p>

        <div class="p">The <span class="ph">Data
                  Collector</span>
            stores the checkpoint metadata in the following path on HDFS or Amazon
            S3:<pre class="pre codeblock">/user/$USER/.streamsets-spark-streaming/&lt;DataCollector WorkerID&gt;/${Kafka topic}</pre>
</div>

        <p class="p">When you run a cluster streaming pipeline on YARN, the <span class="ph">Data
                  Collector</span>
            stores the metadata on HDFS. </p>

        <p class="p">When you run a cluster pipeline on Mesos, the <span class="ph">Data
                  Collector</span>
            can store the metadata on HDFS or Amazon S3.</p>

    </div>

<div class="topic task nested2" id="task_gxz_h1q_k5">
    <h3 class="title topictitle3">Configuring the Location for Mesos</h3>

    
    <div class="body taskbody"><p class="shortdesc">When you run a cluster pipeline on Mesos, the <span class="ph">Data
                  Collector</span> can
        write checkpoint information to either HDFS or Amazon S3. </p>

        <div class="section context">
            <p class="p">To define the location for checkpoint
                storage:</p>

        </div>

        <ol class="ol steps" id="task_gxz_h1q_k5__steps_mt1_l1q_k5"><li class="li step stepexpand">
                <span class="ph cmd">Configure the core-site.xml and hdfs-site.xml files to define where to write
                    the checkpoint information. </span>
                <div class="itemgroup info">For more information about configuring the files, see <a class="xref" href="https://wiki.apache.org/hadoop/AmazonS3" target="_blank">https://wiki.apache.org/hadoop/AmazonS3</a>.</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Store the files within the <span class="ph">Data
                  Collector</span> resources directory.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Enter the location of the files in the <span class="ph menucascade"><span class="ph uicontrol">Cluster</span> &gt; <span class="ph uicontrol">Hadoop/S3 Configuration Directory</span></span> pipeline property.</span>
            </li>
</ol>

    </div>

</div>
</div>
<div class="topic concept nested1" id="concept_xxz_nft_ls">
 <h2 class="title topictitle2">Error Handling Limitations</h2>

 <div class="body conbody">
  <div class="p">Please
      note the following limitations to pipeline configuration options at this time:<ul class="ul" id="concept_xxz_nft_ls__ul_vf1_zft_ls">
        <li class="li"><span class="ph uicontrol">Memory Limit Exceeded</span> - Use the log or log and alert options.
          Stopping the pipeline is not supported at this time. </li>

        <li class="li"><span class="ph uicontrol">Error Records</span> - Write error records to Kafka or discard the
          records. Stopping the pipeline or writing records to file is not supported at this time.
        </li>

      </ul>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_fk4_gd4_1s">
 <h2 class="title topictitle2">Cluster Monitoring</h2>

 <div class="body conbody">
    <p class="p">The <span class="ph">Data
                  Collector</span> console
      allows you to monitor each <span class="ph">Data
                  Collector</span> worker. </p>

    <div class="p">After you start a pipeline, the <span class="ph">Data
                  Collector</span> console
      displays basic monitoring information for the pipeline and links to each <span class="ph">Data
                  Collector</span> worker.
      For monitoring details for a <span class="ph">Data
                  Collector</span> worker,
      click the worker link. You can then view metrics and alerts for the worker. <div class="note note"><span class="notetitle">Note:</span> Metric and
        data alerts are defined for the pipeline, but triggered by individual workers.  When you
        define a metric or data alert, each worker inherits the alert and triggers the alert based
        on the statistics for the worker.</div>
</div>

  </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div>
</body>
</html>